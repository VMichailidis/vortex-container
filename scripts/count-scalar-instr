#! /usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.13"
# dependencies = [
#     "pandas",
# ]
# ///
# uv add --script analyze-logs <package>(== | > | < )<version_number>

# TODO: verify parser
# TODO: Write documentation
import argparse
import sys
import pandas as pd
import re

from pathlib import Path as path


def is_scalar(vec: str | None):
    """Checks if a string with the format {a, b, c, d} is sclalar"""
    if vec is None:
        return None
    elems = vec.strip("{}").split(", ")
    return all(elem == elems[0] for elem in elems)


def parse(file: str):
    """Extracts execution data from input and stores them to a dataframe"""
    op_pattern = re.compile(
        r"""
^DEBUG\sInstr:\s+(?P<instr>\S+)
.*?
cid=(?P<cid>\d),\s*
wid=(?P<wid>\d),\s*
tmask=(?P<tmask>\d+),.*?$
(?:
    \n^DEBUG\s+Src0\s+Reg:\s+x\d+=(?P<src_0>\{.*?\})
)?
(?:
    \n^DEBUG\s+Src1\s+Reg:\s+x\d+=(?P<src_1>\{.*?\})
)?
(?:
    \n^DEBUG\s+Dest\s+Reg:\s+x\d+=(?P<dest>\{.*?\})
)?
""",
        re.MULTILINE | re.VERBOSE,
    )

    with open("run.log", "r") as log:
        log_content = log.read()
        ops = [m.groupdict() for m in op_pattern.finditer(log_content)]
    return pd.DataFrame(ops)


def main(args):
    """Parses the input file and returns the sclarization relevant stats"""
    ops = parse(args["in"])
    ops["scalar_src_0"] = ops["src_0"].apply(is_scalar)
    ops["scalar_src_1"] = ops["src_1"].apply(is_scalar)
    ops["None_only"] = ops.apply(
        lambda x: (x["scalar_src_1"] is None) and (x["scalar_src_0"] is None),
        axis=1,
    )
    ops["scalar_1"] = ops.apply(
        lambda x: x["scalar_src_0"] and (x["scalar_src_1"] is None), axis=1
    )
    ops["scalar_2"] = ops.apply(
        lambda x: (x["scalar_src_0"] and x["scalar_src_1"]), axis=1
    )
    # TODO: calculate the results for src_2
    stats = {
        "None only": ops[["None_only"]].value_counts(),
        "1 scalar": ops[["scalar_1"]].value_counts(),
        "2 scalar": ops[["scalar_2"]].value_counts(),
    }
    print(
        ops[["None_only"]].value_counts(),
        ops[["scalar_1"]].value_counts(),
        ops[["scalar_2"]].value_counts(),
        sep="\n",
    )
    return ops, stats


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument("-i", help="Input File")
    parser.add_argument("-o", help="Output File")
    parser.add_argument(
        "--candidates",
        help="Print Scalarization Candidates",
        action="store_true",
    )
    parser.add_argument(
        "--instruction_count",
        help="Print Instruction Count",
        action="store_true",
    )
    parser.add_argument(
        "--stats",
        help="Print percentage of scalarization candidate",
        action="store_true",
    )

    args = parser.parse_args()

    args_n = {}
    if args.i:
        args_n.update({"in": (path.cwd() / args.i).resolve()})
    else:
        print("Error: No input specified", file=sys.stderr)
        exit(-1)
    if args.o:
        args_n.update({"out": (path.cwd() / args.o).resolve()})
    else:
        args_n.update({"out": (path.cwd() / "./out.csv").resolve()})

    ops, stats = main(args_n)

    inst_count = ops.shape[0]
    const_ops = stats["None only"].get(True)
    unary_ops = stats["1 scalar"].get(True)
    binary_ops = stats["2 scalar"].get(True)
    candidates = (unary_ops + binary_ops) / inst_count * 100
    if not (args.candidates or args.instruction_count or args.stats):
        print(
            f"out of {inst_count} executed commands: \n\
{const_ops} were instructions without input\n\
{unary_ops} were scalar instructions with one input,\n\
{binary_ops} were scalar instructions with two inputs,\n\
{candidates:.1f}% of instructions \
were candidates for scalarization"
        )
        exit(0)

    out = ""
    if args.candidates:
        out += f"{unary_ops + binary_ops}"
    if args.instruction_count:
        out += f", {inst_count}"
    if args.stats:
        out += f", {candidates:.1f}%"
    print(out.strip(", "))

    exit(0)
